{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<H1>PRICE PREDICTION OF PRODUCTS: HACKEREARTH HACKATHON</H1><BR>SUBMISSION-3:MULTIPLE MODELS <BR>GRID SEARCH TRIAL 1<BR>VISUALS NOT INCLUDED"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "IMPORTING FILES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import svm,tree,linear_model,naive_bayes,ensemble,gaussian_process,neighbors\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "source": [
    "READING DATA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6368 entries, 0 to 6367\nData columns (total 15 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Product_id        6368 non-null   object \n 1   Stall_no          6363 non-null   float64\n 2   instock_date      6368 non-null   object \n 3   Market_Category   6368 non-null   int64  \n 4   Customer_name     6157 non-null   object \n 5   Loyalty_customer  6368 non-null   object \n 6   Product_Category  6368 non-null   object \n 7   Grade             6368 non-null   int64  \n 8   Demand            6368 non-null   int64  \n 9   Discount_avail    6330 non-null   float64\n 10  charges_1         6170 non-null   float64\n 11  charges_2 (%)     6163 non-null   float64\n 12  Minimum_price     6330 non-null   float64\n 13  Maximum_price     6025 non-null   float64\n 14  Selling_Price     6327 non-null   float64\ndtypes: float64(7), int64(3), object(5)\nmemory usage: 746.4+ KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3430 entries, 0 to 3429\nData columns (total 14 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   Product_id        3430 non-null   object \n 1   Stall_no          3429 non-null   float64\n 2   instock_date      3430 non-null   object \n 3   Market_Category   3430 non-null   int64  \n 4   Customer_name     3377 non-null   object \n 5   Loyalty_customer  3430 non-null   object \n 6   Product_Category  3430 non-null   object \n 7   Grade             3430 non-null   int64  \n 8   Demand            3430 non-null   int64  \n 9   Discount_avail    3430 non-null   int64  \n 10  charges_1         3394 non-null   float64\n 11  charges_2 (%)     3425 non-null   float64\n 12  Minimum_price     3416 non-null   float64\n 13  Maximum_price     3430 non-null   int64  \ndtypes: float64(4), int64(5), object(5)\nmemory usage: 375.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Product_id  Stall_no             instock_date  Market_Category  \\\n",
       "0  BRAE2NF6JA5GUEXG      37.0  2015-08-22 18:36:12.000                2   \n",
       "1  TUNE8SFB6RJN2HSD      38.0  2016-03-27 21:19:13.000               24   \n",
       "2  BRAEAR7WZPQGPBZU       9.0  2015-08-18 19:25:22.000              447   \n",
       "3  WATDZ2ZQ8JPDHCTJ      50.0  2016-03-28 21:53:01.000               23   \n",
       "4  JWSEBUKYQPMBZ3RK       7.0  2016-03-29 22:58:53.000               63   \n",
       "\n",
       "  Customer_name Loyalty_customer Product_Category  Grade  Demand  \\\n",
       "0      Lillyann              Yes          Fashion      1      68   \n",
       "1         Klynn              Yes          Fashion      0      51   \n",
       "2         Ridge              Yes       Child_care      0      10   \n",
       "3         Abran              Yes      Educational      2      48   \n",
       "4        Dustyn              Yes           Repair      1      35   \n",
       "\n",
       "   Discount_avail  charges_1  charges_2 (%)  Minimum_price  Maximum_price  \\\n",
       "0             0.0      376.0           11.0         2983.0         4713.0   \n",
       "1             0.0      397.0           12.0         7495.0        10352.0   \n",
       "2             0.0      250.0            9.0         5752.0         7309.0   \n",
       "3             0.0      144.0           13.0         5090.0        20814.0   \n",
       "4             1.0      211.0            4.0         2430.0         9261.0   \n",
       "\n",
       "   Selling_Price  \n",
       "0    4185.947700  \n",
       "1    9271.490256  \n",
       "2    6785.701362  \n",
       "3   13028.917824  \n",
       "4     906.553935  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product_id</th>\n      <th>Stall_no</th>\n      <th>instock_date</th>\n      <th>Market_Category</th>\n      <th>Customer_name</th>\n      <th>Loyalty_customer</th>\n      <th>Product_Category</th>\n      <th>Grade</th>\n      <th>Demand</th>\n      <th>Discount_avail</th>\n      <th>charges_1</th>\n      <th>charges_2 (%)</th>\n      <th>Minimum_price</th>\n      <th>Maximum_price</th>\n      <th>Selling_Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BRAE2NF6JA5GUEXG</td>\n      <td>37.0</td>\n      <td>2015-08-22 18:36:12.000</td>\n      <td>2</td>\n      <td>Lillyann</td>\n      <td>Yes</td>\n      <td>Fashion</td>\n      <td>1</td>\n      <td>68</td>\n      <td>0.0</td>\n      <td>376.0</td>\n      <td>11.0</td>\n      <td>2983.0</td>\n      <td>4713.0</td>\n      <td>4185.947700</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TUNE8SFB6RJN2HSD</td>\n      <td>38.0</td>\n      <td>2016-03-27 21:19:13.000</td>\n      <td>24</td>\n      <td>Klynn</td>\n      <td>Yes</td>\n      <td>Fashion</td>\n      <td>0</td>\n      <td>51</td>\n      <td>0.0</td>\n      <td>397.0</td>\n      <td>12.0</td>\n      <td>7495.0</td>\n      <td>10352.0</td>\n      <td>9271.490256</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BRAEAR7WZPQGPBZU</td>\n      <td>9.0</td>\n      <td>2015-08-18 19:25:22.000</td>\n      <td>447</td>\n      <td>Ridge</td>\n      <td>Yes</td>\n      <td>Child_care</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.0</td>\n      <td>250.0</td>\n      <td>9.0</td>\n      <td>5752.0</td>\n      <td>7309.0</td>\n      <td>6785.701362</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WATDZ2ZQ8JPDHCTJ</td>\n      <td>50.0</td>\n      <td>2016-03-28 21:53:01.000</td>\n      <td>23</td>\n      <td>Abran</td>\n      <td>Yes</td>\n      <td>Educational</td>\n      <td>2</td>\n      <td>48</td>\n      <td>0.0</td>\n      <td>144.0</td>\n      <td>13.0</td>\n      <td>5090.0</td>\n      <td>20814.0</td>\n      <td>13028.917824</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JWSEBUKYQPMBZ3RK</td>\n      <td>7.0</td>\n      <td>2016-03-29 22:58:53.000</td>\n      <td>63</td>\n      <td>Dustyn</td>\n      <td>Yes</td>\n      <td>Repair</td>\n      <td>1</td>\n      <td>35</td>\n      <td>1.0</td>\n      <td>211.0</td>\n      <td>4.0</td>\n      <td>2430.0</td>\n      <td>9261.0</td>\n      <td>906.553935</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "source": [
    "CONVERTING DATE FROM OBJECT TO DATE-TIME\n",
    "NEW FEATURE : INSTOCK YEAR "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train_data, test_data]:\n",
    "    data['instock_date'] = data['instock_date'].str.split(\" \", n=1,expand = True)[0]\n",
    "    data['instock_date'] = pd.to_datetime(data['instock_date'])\n",
    "    data['instock_year'] = data['instock_date'].dt.year"
   ]
  },
  {
   "source": [
    "CREATING DUMMY VARIABLES FOR CATAGORIES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Product_id Product_Category  Grade  Discount_avail  charges_1  \\\n",
       "0  BRAE2NF6JA5GUEXG          Fashion      1             0.0      376.0   \n",
       "1  TUNE8SFB6RJN2HSD          Fashion      0             0.0      397.0   \n",
       "2  BRAEAR7WZPQGPBZU       Child_care      0             0.0      250.0   \n",
       "3  WATDZ2ZQ8JPDHCTJ      Educational      2             0.0      144.0   \n",
       "4  JWSEBUKYQPMBZ3RK           Repair      1             1.0      211.0   \n",
       "\n",
       "   charges_2 (%)  Minimum_price  Maximum_price  Selling_Price  instock_year  \\\n",
       "0           11.0         2983.0         4713.0    4185.947700          2015   \n",
       "1           12.0         7495.0        10352.0    9271.490256          2016   \n",
       "2            9.0         5752.0         7309.0    6785.701362          2015   \n",
       "3           13.0         5090.0        20814.0   13028.917824          2016   \n",
       "4            4.0         2430.0         9261.0     906.553935          2016   \n",
       "\n",
       "   Child_care  Cosmetics  Educational  Fashion  Home_decor  Hospitality  \\\n",
       "0           0          0            0        1           0            0   \n",
       "1           0          0            0        1           0            0   \n",
       "2           1          0            0        0           0            0   \n",
       "3           0          0            1        0           0            0   \n",
       "4           0          0            0        0           0            0   \n",
       "\n",
       "   Organic  Pet_care  Repair  Technology  \n",
       "0        0         0       0           0  \n",
       "1        0         0       0           0  \n",
       "2        0         0       0           0  \n",
       "3        0         0       0           0  \n",
       "4        0         0       1           0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product_id</th>\n      <th>Product_Category</th>\n      <th>Grade</th>\n      <th>Discount_avail</th>\n      <th>charges_1</th>\n      <th>charges_2 (%)</th>\n      <th>Minimum_price</th>\n      <th>Maximum_price</th>\n      <th>Selling_Price</th>\n      <th>instock_year</th>\n      <th>Child_care</th>\n      <th>Cosmetics</th>\n      <th>Educational</th>\n      <th>Fashion</th>\n      <th>Home_decor</th>\n      <th>Hospitality</th>\n      <th>Organic</th>\n      <th>Pet_care</th>\n      <th>Repair</th>\n      <th>Technology</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BRAE2NF6JA5GUEXG</td>\n      <td>Fashion</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>376.0</td>\n      <td>11.0</td>\n      <td>2983.0</td>\n      <td>4713.0</td>\n      <td>4185.947700</td>\n      <td>2015</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TUNE8SFB6RJN2HSD</td>\n      <td>Fashion</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>397.0</td>\n      <td>12.0</td>\n      <td>7495.0</td>\n      <td>10352.0</td>\n      <td>9271.490256</td>\n      <td>2016</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BRAEAR7WZPQGPBZU</td>\n      <td>Child_care</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>250.0</td>\n      <td>9.0</td>\n      <td>5752.0</td>\n      <td>7309.0</td>\n      <td>6785.701362</td>\n      <td>2015</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>WATDZ2ZQ8JPDHCTJ</td>\n      <td>Educational</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>144.0</td>\n      <td>13.0</td>\n      <td>5090.0</td>\n      <td>20814.0</td>\n      <td>13028.917824</td>\n      <td>2016</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JWSEBUKYQPMBZ3RK</td>\n      <td>Repair</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>211.0</td>\n      <td>4.0</td>\n      <td>2430.0</td>\n      <td>9261.0</td>\n      <td>906.553935</td>\n      <td>2016</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "full_data = [train_data, test_data]\n",
    "for data in full_data:\n",
    "    data.drop(['Customer_name', 'Loyalty_customer','Stall_no', 'Market_Category', 'Demand','instock_date'], inplace = True, axis = 1)\n",
    "    \n",
    "Product_Category_encoded = pd.get_dummies(train_data['Product_Category'])\n",
    "train_data = pd.concat([train_data,Product_Category_encoded], axis = 1)\n",
    "Product_Category_encoded = pd.get_dummies(test_data['Product_Category'])\n",
    "test_data = pd.concat([test_data,Product_Category_encoded], axis = 1)\n",
    "train_data.head()"
   ]
  },
  {
   "source": [
    "TOTAL NUMBER OF NULL VALUES IN EACH COLUMN OF TRAIN AND TEST DATA\n",
    "TOTAL NUMBER OF NULL VALUES IN EACH PRODUCT CATAGORY WITH RESPECT TO SELECTED COLUMNS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Product_id : 0\nProduct_Category : 0\nGrade : 0\nDiscount_avail : 38\ncharges_1 : 198\ncharges_2 (%) : 205\nMinimum_price : 38\nMaximum_price : 343\nSelling_Price : 41\ninstock_year : 0\n------------------------------\nProduct_id : 0\nProduct_Category : 0\nGrade : 0\nDiscount_avail : 0\ncharges_1 : 36\ncharges_2 (%) : 5\nMinimum_price : 14\nMaximum_price : 0\ninstock_year : 0\n------------------------------\nDiscount_avail\nChild_care:  6\nCosmetics:  2\nEducational:  5\nFashion:  4\nHome_decor:  5\nHospitality:  6\nOrganic:  2\nPet_care:  0\nRepair:  6\nTechnology:  2\n----------------------\ncharges_1\nChild_care:  18\nCosmetics:  14\nEducational:  17\nFashion:  25\nHome_decor:  29\nHospitality:  22\nOrganic:  13\nPet_care:  15\nRepair:  23\nTechnology:  22\n----------------------\ncharges_2 (%)\nChild_care:  20\nCosmetics:  26\nEducational:  16\nFashion:  19\nHome_decor:  22\nHospitality:  23\nOrganic:  23\nPet_care:  22\nRepair:  23\nTechnology:  11\n----------------------\nMinimum_price\nChild_care:  2\nCosmetics:  2\nEducational:  5\nFashion:  2\nHome_decor:  4\nHospitality:  2\nOrganic:  8\nPet_care:  4\nRepair:  5\nTechnology:  4\n----------------------\nMaximum_price\nChild_care:  42\nCosmetics:  32\nEducational:  35\nFashion:  36\nHome_decor:  27\nHospitality:  35\nOrganic:  22\nPet_care:  29\nRepair:  40\nTechnology:  45\n----------------------\n=========================\nDiscount_avail\nChild_care:  0\nCosmetics:  0\nEducational:  0\nFashion:  0\nHome_decor:  0\nHospitality:  0\nOrganic:  0\nPet_care:  0\nRepair:  0\nTechnology:  0\n----------------------\ncharges_1\nChild_care:  5\nCosmetics:  5\nEducational:  5\nFashion:  5\nHome_decor:  5\nHospitality:  1\nOrganic:  2\nPet_care:  0\nRepair:  4\nTechnology:  4\n----------------------\ncharges_2 (%)\nChild_care:  0\nCosmetics:  1\nEducational:  1\nFashion:  0\nHome_decor:  0\nHospitality:  1\nOrganic:  2\nPet_care:  0\nRepair:  0\nTechnology:  0\n----------------------\nMinimum_price\nChild_care:  1\nCosmetics:  1\nEducational:  1\nFashion:  1\nHome_decor:  3\nHospitality:  0\nOrganic:  2\nPet_care:  1\nRepair:  3\nTechnology:  1\n----------------------\nMaximum_price\nChild_care:  0\nCosmetics:  0\nEducational:  0\nFashion:  0\nHome_decor:  0\nHospitality:  0\nOrganic:  0\nPet_care:  0\nRepair:  0\nTechnology:  0\n----------------------\n=========================\n"
     ]
    }
   ],
   "source": [
    "for data in full_data:\n",
    "    for x in data.columns:\n",
    "        print(\"{col} : {val}\".format(col = x, val = data[x].isna().sum()))\n",
    "    print('-'*30)\n",
    "\n",
    "listProd = ['Child_care','Cosmetics', 'Educational','Fashion','Home_decor',\t'Hospitality',\t'Organic',\t'Pet_care',\t'Repair','Technology']\n",
    "nullCols = ['Discount_avail','charges_1','charges_2 (%)','Minimum_price','Maximum_price']\n",
    "for data in full_data:\n",
    "    for y in nullCols:\n",
    "        print(y)\n",
    "        for x in listProd:\n",
    "            print('{col}:  {val}'.format(col = x, val=(data['Product_Category'].loc[data[y].isna()] ==x).sum()))\n",
    "        print('----------------------')\n",
    "    print('=========================')\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "DROPPING NULL ROWS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Product_id            0\n",
       "Product_Category      0\n",
       "Grade                 0\n",
       "Discount_avail       38\n",
       "charges_1           198\n",
       "charges_2 (%)       205\n",
       "Minimum_price        38\n",
       "Maximum_price       343\n",
       "Selling_Price        41\n",
       "instock_year          0\n",
       "Child_care            0\n",
       "Cosmetics             0\n",
       "Educational           0\n",
       "Fashion               0\n",
       "Home_decor            0\n",
       "Hospitality           0\n",
       "Organic               0\n",
       "Pet_care              0\n",
       "Repair                0\n",
       "Technology            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'Discount_avail': train_data['Discount_avail'].mean(), 'charges_1': train_data['charges_1'].mean(), 'charges_2 (%)':train_data['charges_2 (%)'].median() , 'Minimum_price': train_data['Minimum_price'].median(),'Maximum_price':train_data['Maximum_price'].median()}\n",
    "train_data.fillna(value=values,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'Discount_avail': test_data['Discount_avail'].mean(), 'charges_1': test_data['charges_1'].mean(), 'charges_2 (%)':test_data['charges_2 (%)'].median(),'Minimum_price': test_data['Minimum_price'].median()}\n",
    "test_data.fillna(value=values,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Product_id          0\n",
       "Product_Category    0\n",
       "Grade               0\n",
       "Discount_avail      0\n",
       "charges_1           0\n",
       "charges_2 (%)       0\n",
       "Minimum_price       0\n",
       "Maximum_price       0\n",
       "Selling_Price       0\n",
       "instock_year        0\n",
       "Child_care          0\n",
       "Cosmetics           0\n",
       "Educational         0\n",
       "Fashion             0\n",
       "Home_decor          0\n",
       "Hospitality         0\n",
       "Organic             0\n",
       "Pet_care            0\n",
       "Repair              0\n",
       "Technology          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_data = train_data[~train_data['Selling_Price'].isna()]\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "source": [
    "PREPARING TRAINING DATA AND TESTING DATA FOR MODEL SELECTION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[train_data['Selling_Price']>0]\n",
    "features = ['Grade', 'Discount_avail',\n",
    "       'charges_1', 'charges_2 (%)', 'Minimum_price', 'Maximum_price',\n",
    "       'instock_year', 'Child_care', 'Cosmetics',\n",
    "       'Educational', 'Fashion', 'Home_decor', 'Hospitality', 'Organic',\n",
    "       'Pet_care', 'Repair', 'Technology']\n",
    "X = train_data[features]\n",
    "y = train_data['Selling_Price']\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "source": [
    "RMLSE SCORE FUNCTION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "def RMSLE(y_true:np.ndarray, y_pred:np.ndarray) -> np.float64:\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "source": [
    "TESTING REGRESSION MODELS FOR BEST MODEL SELECTION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "    ensemble.ExtraTreesRegressor(),\n",
    "    ensemble.RandomForestRegressor(),\n",
    "    XGBRegressor(),\n",
    "    LGBMRegressor()    \n",
    "    ]"
   ]
  },
  {
   "source": [
    "CHECKING MINIMUM RMLSE OUT OF ALL MODEL PREDICTIONS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: -4969.35 (+/- 2901.76)\n",
      "Accuracy: -4991.96 (+/- 2935.19)\n",
      "Accuracy: -5085.11 (+/- 2780.36)\n",
      "Accuracy: -4921.08 (+/- 2865.27)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for model in MLA:\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring = 'max_error')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = [\n",
    "    [{\n",
    "        'n_estimators' : [150],\n",
    "         'max_features': [None],\n",
    "         'max_depth': [None],\n",
    "         'min_samples_split': [2],\n",
    "         'n_jobs' : [-1]\n",
    "    }],\n",
    "    \n",
    "    [{\n",
    "        'n_estimators' : [10, 50, 100, 150],\n",
    "        'max_depth' : [None],\n",
    "        'max_features': ('auto', None),\n",
    "        'min_samples_split': [2],\n",
    "        'n_jobs' : [-1]\n",
    "    }],\n",
    "\n",
    "    [{\n",
    "        'learning_rate': [.03, 0.05, .07],\n",
    "        'max_depth' : [3,5,7,9],\n",
    "        'gamma' : [0,0.01,0.1],\n",
    "        'colsample_bytree': [0.5,0.7,1.0],\n",
    "        'objective': ['reg:linear'],\n",
    "        'eval_metric' : ['mae'],\n",
    "    }],\n",
    "\n",
    "    [{\n",
    "        'boosting_type': ('gbdt','rf','dart','goss'),\n",
    "        'num_leaves': [31,70,100,150],\n",
    "        'max_depth' : [3,5,7,9],\n",
    "        'learning_rate' : [.03, 0.05, .07],\n",
    "        'colsample_bytree' : [0.5,0.7,1.0],\n",
    "        'objective' : ['regression'],\n",
    "        'n_estimators': [50,100,150,200],\n",
    "    }]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-3420.9643569582895\n{'max_depth': None, 'max_features': None, 'min_samples_split': 2, 'n_estimators': 150, 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{\n",
    "        'n_estimators' : [150],\n",
    "         'max_features': [None],\n",
    "         'max_depth': [None],\n",
    "         'min_samples_split': [2],\n",
    "         'n_jobs' : [-1]\n",
    "    }]\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "best_search = GridSearchCV(estimator = ensemble.ExtraTreesRegressor(), param_grid=parameters, scoring='max_error',cv = cv)\n",
    "best_search.fit(X_train,y_train)\n",
    "print(best_search.best_score_)\n",
    "print(best_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-3798.8777967906667\n{'max_depth': None, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 50, 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{\n",
    "        'n_estimators' : [10, 50, 100, 150],\n",
    "        'max_depth' : [None],\n",
    "        'max_features': ('auto', None),\n",
    "        'min_samples_split': [2],\n",
    "        'n_jobs' : [-1]\n",
    "    }]\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "best_search = GridSearchCV(estimator = ensemble.RandomForestRegressor(), param_grid=parameters, scoring='max_error',cv = cv)\n",
    "best_search.fit(X_train,y_train)\n",
    "print(best_search.best_score_)\n",
    "print(best_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-3903.6790135651195\n{'colsample_bytree': 0.5, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200, 'num_leaves': 100, 'objective': 'regression'}\n"
     ]
    }
   ],
   "source": [
    "parameters = [{\n",
    "        'max_depth' : [3,5,7],\n",
    "        'num_leaves':[100,150,200],\n",
    "        'learning_rate' : [.03, 0.05, .07],\n",
    "        'colsample_bytree' : [0.5,0.7,1.0],\n",
    "        'objective' : ['regression'],\n",
    "        'n_estimators': [50,100,150,200],\n",
    "    }]\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "best_search = GridSearchCV(estimator = LGBMRegressor(), param_grid=parameters, scoring='max_error',cv = cv)\n",
    "best_search.fit(X_train,y_train)\n",
    "print(best_search.best_score_)\n",
    "print(best_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = best_search.predict(X_test)\n",
    "# data = {'y-test':y_test, 'predictions':pred}\n",
    "# df = pd.DataFrame(data=data, columns=['y-test','predictions'])\n",
    "# df = df[df['predictions']>0]\n",
    "# score = RMSLE(df['y-test'], df['predictions'])\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_params = {'colsample_bytree': 0.7, 'max_depth': 25, 'min_split_gain': 0.3, 'n_estimators': 700, 'num_leaves': 50, 'reg_alpha': 1.1, 'reg_lambda': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
    "# features = ['Grade', 'Discount_avail',\n",
    "#        'charges_1', 'charges_2 (%)', 'Minimum_price', 'Maximum_price',\n",
    "#        'instock_year', 'Child_care', 'Cosmetics',\n",
    "#        'Educational', 'Fashion', 'Home_decor', 'Hospitality', 'Organic',\n",
    "#        'Pet_care', 'Repair', 'Technology']\n",
    "# x = test_data[features]\n",
    "# predictions = best_search.predict(x)\n",
    "# test_data['Selling_Price'] = predictions\n",
    "# data = {'Product_id':test_data['Product_id'], 'Selling_Price':test_data['Selling_Price']}\n",
    "# submissions_df = pd.DataFrame(data= data, columns = ['Product_id', 'Selling_Price'])\n",
    "# submissions_df.to_csv(path_or_buf='/Users/username/Desktop/source/submission.csv')"
   ]
  }
 ]
}